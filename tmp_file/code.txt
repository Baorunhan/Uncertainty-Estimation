        # global2keyego = torch.inverse(keyego2global.double())   # (B, 1, 4, 4)  # brh
        global2keyego = torch.tensor([[[[ 8.7724e-01, -4.7973e-01, -1.7649e-02,  2.6427e+02],
          [ 4.7987e-01,  8.7733e-01,  4.8901e-03, -1.7334e+03],
          [ 1.3138e-02, -1.2759e-02,  9.9983e-01,  1.3143e+01],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]]]],


  post_rots_inv = torch.tensor([[2.2727, 0.0000, 0.0000],
          [0.0000, 2.2727, 0.0000],
          [0.0000, 0.0000, 1.0000]]).unsqueeze(0).unsqueeze(0).cuda()  # (1, 1, 3, 3)
        post_rots_inv_tensor = post_rots_inv.repeat(1, 6, 1, 1)
        
        
        # points = torch.inverse(post_rots).view(B, N, 1, 1, 1, 3, 3)\
        #     .matmul(points.unsqueeze(-1))  # brh
        points = post_rots_inv_tensor.view(B, N, 1, 1, 1, 3, 3)\
            .matmul(points.unsqueeze(-1))

 cam2imgs_inv_tensor = torch.tensor([[[[ 7.9500e-04,  0.0000e+00, -6.5766e-01],
          [ 0.0000e+00,  7.9500e-04, -3.5848e-01],
          [ 0.0000e+00,  0.0000e+00,  1.0000e+00]],

         [[ 7.9820e-04,  0.0000e+00, -6.5979e-01],
          [ 0.0000e+00,  7.9820e-04, -3.7514e-01],
          [ 0.0000e+00,  0.0000e+00,  1.0000e+00]],

         [[ 7.9570e-04,  0.0000e+00, -6.5072e-01],
          [ 0.0000e+00,  7.9570e-04, -3.5962e-01],
          [ 0.0000e+00,  0.0000e+00,  1.0000e+00]],

         [[ 7.9682e-04,  0.0000e+00, -6.6102e-01],
          [ 0.0000e+00,  7.9682e-04, -3.7225e-01],
          [ 0.0000e+00,  0.0000e+00,  1.0000e+00]],

         [[ 1.2549e-03,  0.0000e+00, -1.0764e+00],
          [ 0.0000e+00,  1.2549e-03, -5.9843e-01],
          [ 0.0000e+00,  0.0000e+00,  1.0000e+00]],

         [[ 8.0002e-04,  0.0000e+00, -6.6032e-01],
          [ 0.0000e+00,  8.0002e-04, -3.7005e-01],
          [ 0.0000e+00,  0.0000e+00,  1.0000e+00]]]]).cuda()  # (1, 6, 3, 3)
        # combine = sensor2ego[:, :, :3, :3].matmul(torch.inverse(cam2imgs)) # brh
        combine = sensor2ego[:, :, :3, :3].matmul((cam2imgs_inv_tensor))
